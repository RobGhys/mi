{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Tuple"
   ],
   "id": "52b170cdb4ee3d9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ],
   "id": "c396bf5d702620a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f'{len(text)}')",
   "id": "c3f2feb694374cf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(text[:1000])",
   "id": "d4eb617741dab85d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"Vocabulary ({vocab_size} elements): {''.join(chars)}\")"
   ],
   "id": "8e6b93fd460654d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}"
   ],
   "id": "8e710f3b6d0a5c6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Encoder (str --> list[int])\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "\n",
    "# Decoder (list[int] --> str)\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "ex: str = 'test de texte.'\n",
    "print(encode(ex))\n",
    "print(decode(encode(ex)))"
   ],
   "id": "e15b8fdcbe69af6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # tensor representation of the 1000 first data"
   ],
   "id": "f6f6cd135a9a2a36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split train/val",
   "id": "4aef33c7c4cce487"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "valid_data = data[n:]"
   ],
   "id": "cd19686c3a82ff3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "block_size = 8\n",
    "train_data[: block_size + 1]"
   ],
   "id": "c203f1ca8e7f693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x = train_data[: block_size]\n",
    "y = train_data[1: block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'When input is {context}, the  target is: {target}')"
   ],
   "id": "baf272be4d179926"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size: int = 4\n",
    "\n",
    "def get_batch(split: str, debug: bool = False) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    data = train_data if split == 'train' else valid_data\n",
    "    # Get random values between 0 and [size dataset - block_size], with shape (bs, )\n",
    "    idx = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    # This is the starting position in 'data'\n",
    "    if debug:\n",
    "        print(f'{idx=}')\n",
    "        print(f'This should exactly be the first value of the first element in \"x\" tensor (24 with 1337 as seed) -> {data[idx[0]]}')\n",
    "        print(f'This is the LAST value of the first element in \"y\" tensor.{data[idx[0] + block_size]}')\n",
    "    x = torch.stack([data[i:i + block_size] for i in idx])\n",
    "    y = torch.stack([data[i+1 : i + block_size + 1] for i in idx])\n",
    "\n",
    "    return x, y"
   ],
   "id": "28f742137bd8fa47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "xb, yb = get_batch(split='train')\n",
    "print(f'inputs:\\n{xb.shape}\\n{xb}')\n",
    "print(f'targets:\\n{yb.shape}\\n{yb}')"
   ],
   "id": "f40e33aa9f84d2b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"When input is {context.tolist()} the target: {target}\")"
   ],
   "id": "16729f859718e515"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(xb) # our input to the transformer",
   "id": "2da84c3848b06b78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table: nn.Embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx: torch.Tensor, targets: torch.Tensor | None = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # shape (bs, t, c) where bs is batch size 4, t is temporal dimension 8, and c is channel dimension = vocab_size = 65\n",
    "        logits: torch.Tensor = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "            return logits, loss\n",
    "\n",
    "        bs, t, c = logits.shape\n",
    "        # shape (bs*t, c) = (32, 65)\n",
    "        logits = logits.view(bs * t, c)\n",
    "        # from shape (bs, t) to (bs*t) = (32)\n",
    "        targets = targets.view(bs * t)\n",
    "\n",
    "        # shape (\n",
    "        loss: torch.Tensor = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    # continues the generation for a batch, in the time dimension\n",
    "    def generate(self, idx: torch.Tensor, max_new_tokens: int):\n",
    "        # idx has shape (b, t), and is an array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the preds\n",
    "            logits, loss = self(idx)\n",
    "\n",
    "            # keep last time step only\n",
    "            # shape (b, c)\n",
    "            logits = logits[:, -1, :]\n",
    "            # shape (b, c)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "            # sample from distribution\n",
    "            # shape (b, 1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to running sequence -> concatenate along time axis\n",
    "            # shape (b, t+1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ],
   "id": "d58ec557ade325e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "m = BigramLanguageModel(vocab_size=vocab_size)\n",
    "results: Tuple[torch.Tensor, torch.Tensor] = m(xb, yb)"
   ],
   "id": "50d30f6636fde80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(f'loss: {results[1]=} | shape logits: {results[0].shape}')",
   "id": "9b75b1f18a677cd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "# index into 0th row -> we work with batches and only get the first one\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ],
   "id": "dd4bf8fd73e2ac16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)",
   "id": "936a3bfc1326ff46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size: int = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # eval the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ],
   "id": "de371d3a97bd6ba0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=400)[0].tolist()))"
   ],
   "id": "9c848f8387a6c810"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Self-Attention: the mathematical trick",
   "id": "d235f339dade3b48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "torch.manual_seed(1337)\n",
    "# batch, time, channels\n",
    "b, t, c = 4, 8, 2\n",
    "x = torch.rand(b, t, c)\n",
    "x.shape"
   ],
   "id": "a5f6467daba27c4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# We want x[b, t] = mean_i{i<=t} x[b,i]\n",
    "# bow : bag of words\n",
    "x_bow = torch.zeros((b, t, c))\n",
    "\n",
    "# iterate over batch dimension\n",
    "for _b in range(b):\n",
    "    # iterate over time dimension\n",
    "    for _t in range(t):\n",
    "        # (_t, c)\n",
    "        x_prev = x[_b, :_t+1]\n",
    "        x_bow[_b, _t] = torch.mean(x_prev, 0)"
   ],
   "id": "bab69f2b9fa5648"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "16d6cdfa029a8cb6"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
